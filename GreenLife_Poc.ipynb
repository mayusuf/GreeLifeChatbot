{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Packages**"
      ],
      "metadata": {
        "id": "gmWjwIkNJ1rY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "apoiXN3Iv78O",
        "outputId": "d7b0b791-433f-4fcd-d37f-ccdd0491c709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ied2fq62\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ied2fq62\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.34)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.56)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.27.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.25)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.63)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.34)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.17)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.9.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.9.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "pip install langgraph langchain-core langchain-community langchain huggingface_hub langchain-google-genai gradio sentence-transformers faiss-cpu git+https://github.com/openai/whisper.git ffmpeg-python gTTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQDwOSSS1icy"
      },
      "source": [
        "# **LITERATURE**\n",
        "\n",
        "The following mental health workflow model has the following characteristics:\n",
        "\n",
        "**FEATURES:**\n",
        "- model = gemini-1.5-flash free (It was chosen because it is compatible with Langchain)\n",
        "- embedding = all-MiniLM-L6-v2\n",
        "- vectore_store = FAISS\n",
        "- average processing time = 25 seconds\n",
        "\n",
        "**ADDITIONAL:**\n",
        "2. Prompt Engineer = added a more detailed description of the topic to generate warm responses without losing professionalism\n",
        "3. Graph = implemented a workflow graph in HTML to view the outcome\n",
        "\n",
        "**Gemini Free LIMITATION:**\n",
        "- RATE LIMITS: 15 RPM\n",
        "- 1,000,000 TPM\n",
        "- 1,500 RPD\n",
        "- PRICE (INPUT): Free of charge\n",
        "- PRICE (OUTPUT): Free of charge\n",
        "- GROUNDING WITH GOOGLE SEARCH: Not available"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Packages and Libraries**"
      ],
      "metadata": {
        "id": "FS4JFIRoFnly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing import TypedDict, Annotated, Optional\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.messages import AIMessage\n",
        "from dotenv import load_dotenv\n",
        "from google import genai\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import drive, userdata\n",
        "import logging\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "import gradio as gr\n",
        "import os"
      ],
      "metadata": {
        "id": "9ZNwMMoyFsjx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "metadata": {
        "id": "6yBHs57eGRcG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mount Google Drive**"
      ],
      "metadata": {
        "id": "9WAb5ZtxGgKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    logger.info(\"Google Drive mounted successfully\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to mount Google Drive: {str(e)}\")\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WjXBNvAGfUe",
        "outputId": "89a16c87-49ab-4f21-d8a6-ce3c51f78cac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGOWwDJWS4Qs"
      },
      "source": [
        "## **LOAD MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5zHUJnxK0iUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d20867-9f78-4bad-8226-30f5bcde285a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:.env file not found at /content/drive/MyDrive/OMDENA/MENTAL/gemini/.env. Falling back to Colab secrets.\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables\n",
        "route = \"/content/drive/MyDrive/OMDENA/MENTAL/gemini/.env\"\n",
        "if os.path.exists(route):\n",
        "    load_dotenv(dotenv_path=route)\n",
        "    logger.info(f\".env file loaded from {route}\")\n",
        "else:\n",
        "    logger.warning(f\".env file not found at {route}. Falling back to Colab secrets.\")\n",
        "\n",
        "# Get API key (try .env first, then Colab secrets)\n",
        "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "if not api_key:\n",
        "    try:\n",
        "        api_key = userdata.get('GOOGLE_API_KEY')\n",
        "        logger.info(\"API key loaded from Colab secrets\")\n",
        "    except:\n",
        "        logger.error(\"GOOGLE_API_KEY not found in .env or Colab secrets\")\n",
        "        raise ValueError(\n",
        "            \"GOOGLE_API_KEY is required. Please set it in /content/drive/MyDrive/OMDENA/MENTAL/gemini/.env \"\n",
        "            \"or add it to Colab secrets under the name 'GOOGLE_API_KEY'. \"\n",
        "            \"Get an API key from https://console.cloud.google.com/apis/credentials\"\n",
        "        )\n",
        "\n",
        "# Initialize LLM\n",
        "try:\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0, google_api_key=api_key)\n",
        "    logger.info(\"ChatGoogleGenerativeAI initialized successfully\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to initialize ChatGoogleGenerativeAI: {str(e)}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCy6iVcfTDBT"
      },
      "source": [
        "## **LOAD DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tedQeTDjsppU"
      },
      "outputs": [],
      "source": [
        "# Load existing datasets\n",
        "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRGbYKgw5x2xteCHSjLhkY5FHTPjtVnvBkN_5m2p6clfdUJK77CLDRSdq5RbPygNygaTFsK3xghrfi4/pub?output=csv'\n",
        "try:\n",
        "    df1 = pd.read_csv(url)\n",
        "    logger.info(\"Google Sheets dataset loaded\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to load Google Sheets dataset: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "path = kagglehub.dataset_download(\"emirhanai/social-media-usage-and-emotional-well-being\")\n",
        "path_ = \"/kaggle/input/social-media-usage-and-emotional-well-being\"\n",
        "try:\n",
        "    df2 = pd.read_csv(f\"{path_}/train.csv\")\n",
        "    logger.info(\"Kaggle dataset loaded\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to load Kaggle dataset: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Load new dataset (mental_health_cases.csv)\n",
        "# new_dataset_path = \"/content/sample_data/mental_health_cases.csv\"\n",
        "# try:\n",
        "#     df3 = pd.read_csv(new_dataset_path)\n",
        "#     logger.info(\"Mental health cases dataset loaded\")\n",
        "# except Exception as e:\n",
        "#     logger.error(f\"Failed to load mental_health_cases.csv: {str(e)}\")\n",
        "#     raise\n",
        "\n",
        "# Convert rows to documents\n",
        "def create_documents(df, content_column=None):\n",
        "    documents = []\n",
        "    for index, row in df.iterrows():\n",
        "        if content_column:\n",
        "            content = str(row[content_column])\n",
        "        else:\n",
        "            content = \"\".join(str(value) for value in row)\n",
        "        documents.append(Document(page_content=content))\n",
        "    return documents\n",
        "\n",
        "# Create documents from all datasets\n",
        "docs1 = create_documents(df1, content_column=\"Comments\")\n",
        "docs2 = create_documents(df2)\n",
        "all_docs = docs1 + docs2\n",
        "logger.info(f\"Created {len(all_docs)} documents from datasets\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIKGKqHCS_MI"
      },
      "source": [
        "## **CODE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0B4t2Sswt-NZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "outputId": "f4d8ba63-7533-400a-809a-9196bcc7a3e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bb19d2727adb65d8ce.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bb19d2727adb65d8ce.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I understand you're feeling overwhelmed and unable to focus at work.  That's incredibly stressful, especially at age 50.  While the provided documents discuss internet addiction and obsessive-compulsive disorder,  your description doesn't directly suggest either of those conditions.  However, feeling overwhelmed and unable to focus can be a symptom of various things, including stress itself, and possibly even burnout.\n",
            "\n",
            "It's important to address this.  Here are a few suggestions:\n",
            "\n",
            "* **Prioritize tasks:**  Try breaking down your workload into smaller, more manageable tasks.  Focus on completing one at a time, rather than feeling overwhelmed by the whole picture.  This can help improve focus.\n",
            "\n",
            "* **Time management techniques:** Explore techniques like the Pomodoro Technique (working in focused bursts with short breaks) to improve concentration and prevent burnout.\n",
            "\n",
            "* **Stress reduction techniques:**  Incorporate stress-reducing activities into your daily routine. This could include exercise, meditation, spending time in nature, or engaging in hobbies you enjoy.  Even short breaks for deep breathing can make a difference.\n",
            "\n",
            "* **Seek professional help:** If these strategies don't help, or if the feeling of overwhelm persists, consider talking to a therapist or counselor. They can help you identify the root cause of your stress and develop coping mechanisms.  They can also rule out any underlying conditions that might be contributing to your symptoms.\n",
            "\n",
            "Remember, seeking help is a sign of strength, not weakness.  Taking care of your mental well-being is crucial, especially when facing significant work-related stress.\n"
          ]
        }
      ],
      "source": [
        "# Define graph state\n",
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "    age: int\n",
        "    gender: str\n",
        "    language: Optional[str]\n",
        "    emotion: str\n",
        "    query: str\n",
        "    docs: list\n",
        "    next: str\n",
        "\n",
        "# Initialize FAISS vector store\n",
        "def create_faiss_db(documents):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
        "    split_docs = splitter.split_documents(documents)\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vector_store = FAISS.from_documents(split_docs, embeddings)\n",
        "    vector_store.save_local(\"/content/drive/MyDrive/OMDENA/MENTAL/faiss_index\")\n",
        "    logger.info(\"FAISS vector store created and saved\")\n",
        "    return vector_store\n",
        "\n",
        "def get_vector_store(documents):\n",
        "    faiss_index_path = \"/content/drive/MyDrive/OMDENA/MENTAL/faiss_index\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    if os.path.exists(faiss_index_path):\n",
        "        vector_store = FAISS.load_local(faiss_index_path, embeddings, allow_dangerous_deserialization=True)\n",
        "        logger.info(\"Loaded existing FAISS vector store\")\n",
        "    else:\n",
        "        vector_store = create_faiss_db(documents)\n",
        "    return vector_store\n",
        "\n",
        "# Node: InputCollector\n",
        "def input_collector(state: GraphState) -> GraphState:\n",
        "    return state\n",
        "\n",
        "# Node: ValidateInput\n",
        "def validate_input(state: GraphState) -> dict:\n",
        "    if state['age'] > 0 and state['gender'] in ['male', 'female'] and state['emotion']:\n",
        "        return {\"next\": \"RetrieveDocs\"}\n",
        "    return {\"next\": END}\n",
        "\n",
        "# Node: RetrieveDocs\n",
        "def retrieve_docs(state: GraphState) -> GraphState:\n",
        "    vector_store = get_vector_store(all_docs)\n",
        "    retriever = vector_store.as_retriever()\n",
        "    docs = retriever.get_relevant_documents(state[\"query\"])\n",
        "    state[\"docs\"] = docs\n",
        "    logger.info(f\"Retrieved {len(docs)} documents for query: {state['query']}\")\n",
        "    return state\n",
        "\n",
        "# Node: SystemReplyGenerator\n",
        "def generate_reply(state: GraphState) -> GraphState:\n",
        "    base_context = \"\"\"\n",
        "You are a virtual emotional wellness agent designed to help people understand and improve their mental health by providing empathetic, warm, and professional responses to various emotions. Respond with accessible and understandable strategies and support tailored to the emotions indicated by the user.\n",
        "\n",
        "# Overview\n",
        "For each emotion mentioned by users, respond with empathy and provide practical strategies that can help them manage that emotion in a healthy way. Maintain a warm but professional tone, using emoticons sparingly to convey humanity without losing professionalism.\n",
        "\n",
        "# Specific Details\n",
        "1. **Tone**: Empathetic, friendly, and encouraging, but avoid being too casual.\n",
        "2. **Helpful Content**: Combination of emotional support (encouraging words) and practical strategies (techniques, activities, small actions).\n",
        "3. **Emoticons**: Use them sparingly (1-2 maximum per response) according to the supportive tone.\n",
        "4. **Personalized Strategies**: Make sure you tailor your recommendations to the specific emotion indicated by the user.\n",
        "5. **Accessible Language**: Make sure your explanations and advice are clear, simple, and free of complicated technical terms.\n",
        "\n",
        "# Possible Emotions to Manage\n",
        "- Stress\n",
        "- Anxiety\n",
        "- Depression\n",
        "- Sadness\n",
        "- Overwhelm\n",
        "- Exhaustion\n",
        "- Anger\n",
        "- Feeling Lonely\n",
        "- Confusion\n",
        "- Neutral/Unsure\n",
        "\n",
        "# Output Format\n",
        "Write a response for each emotion with a warm tone, structured in the following parts:\n",
        "1. **Emotional Acknowledgment**: Acknowledge how the user feels, validating their emotions.\n",
        "2. **Emotional Support**: Show empathy and provide words of encouragement.\n",
        "3. **Practical Actions**: Suggest concrete strategies (at least 2-3) they can put into practice, incorporating relevant suggestions from retrieved documents where applicable.\n",
        "4. **Positive Closing**: End with an encouraging statement.\n",
        "\n",
        "# Notes\n",
        "- Incorporate specific suggestions from retrieved documents (e.g., comments from mental_health_cases.csv) when they align with the user's emotion and query.\n",
        "- Ensure responses are varied and not repetitive, using retrieved documents as additional context.\n",
        "- Maintain a genuine tone and avoid clinical diagnoses.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"User (Age: {state['age']}, Gender: {state['gender']}, Emotion: {state['emotion']}): {state['query']}\\n\"\n",
        "        f\"Generate a response based on all the instructions in the base context with the information in {state['docs']}. \"\n",
        "        f\"The response must incorporate relevant suggestions from the retrieved documents, especially from the mental health dataset, when applicable.\"\n",
        "    )\n",
        "    language = state.get(\"language\", \"English\")\n",
        "    if language.lower() != \"english\":\n",
        "        prompt += f\" Translate the final answer to {language}.\"\n",
        "    try:\n",
        "        response = llm.invoke(prompt)\n",
        "        reply = response.content if hasattr(response, \"content\") else response\n",
        "        state[\"messages\"].append(AIMessage(content=reply))\n",
        "        logger.info(\"Generated response successfully\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to generate response: {str(e)}\")\n",
        "        reply = \"I'm sorry, I couldn't generate a response. Please try again.\"\n",
        "        state[\"messages\"].append(AIMessage(content=reply))\n",
        "    if any(term in reply.lower() for term in [\"stress\", \"focus\", \"overwhelmed\"]):\n",
        "        state[\"next\"] = \"relevant\"\n",
        "    else:\n",
        "        state[\"next\"] = \"irrelevant\"\n",
        "    return state\n",
        "\n",
        "# Node: RewriteReply\n",
        "def rewrite_reply(state: GraphState) -> GraphState:\n",
        "    previous_reply = state['messages'][-1].content if state['messages'] else \"\"\n",
        "    prompt = f\"Rewrite this reply to be more aligned with the user's emotional state ({state['emotion']}): {previous_reply}\"\n",
        "    try:\n",
        "        response = llm.invoke(prompt)\n",
        "        reply = response.content if hasattr(response, \"content\") else response\n",
        "        state[\"messages\"].append(AIMessage(content=reply))\n",
        "        logger.info(\"Rewrote response successfully\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to rewrite response: {str(e)}\")\n",
        "        reply = \"I'm sorry, I couldn't rewrite the response. Please try again.\"\n",
        "        state[\"messages\"].append(AIMessage(content=reply))\n",
        "    state[\"next\"] = \"relevant\"\n",
        "    return state\n",
        "\n",
        "# Node: ConversationHandler\n",
        "def conversation_handler(state: GraphState) -> dict:\n",
        "    latest = state['messages'][-1].content if state['messages'] else \"\"\n",
        "    if any(x in latest.lower() for x in [\"exit\", \"quit\", \"bye\"]):\n",
        "        return {\"next\": END}\n",
        "    return {\"next\": \"FollowUpAnalyzer\"}\n",
        "\n",
        "# Node: FollowUpAnalyzer\n",
        "def follow_up_analyzer(state: GraphState) -> GraphState:\n",
        "    return state\n",
        "\n",
        "# Build the LangGraph\n",
        "workflow = StateGraph(GraphState)\n",
        "workflow.add_node(\"InputCollector\", RunnableLambda(input_collector))\n",
        "workflow.add_node(\"ValidateInput\", RunnableLambda(validate_input))\n",
        "workflow.add_node(\"RetrieveDocs\", RunnableLambda(retrieve_docs))\n",
        "workflow.add_node(\"SystemRepliesGenerator\", RunnableLambda(generate_reply))\n",
        "workflow.add_node(\"RewriteReply\", RunnableLambda(rewrite_reply))\n",
        "workflow.add_node(\"ConversationHandler\", RunnableLambda(conversation_handler))\n",
        "workflow.add_node(\"FollowUpAnalyzer\", RunnableLambda(follow_up_analyzer))\n",
        "\n",
        "# Edges\n",
        "workflow.set_entry_point(\"InputCollector\")\n",
        "workflow.add_edge(\"InputCollector\", \"ValidateInput\")\n",
        "workflow.add_conditional_edges(\"ValidateInput\", lambda x: x[\"next\"])\n",
        "workflow.add_edge(\"RetrieveDocs\", \"SystemRepliesGenerator\")\n",
        "workflow.add_conditional_edges(\"SystemRepliesGenerator\", lambda x: x[\"next\"])\n",
        "workflow.add_edge(\"RewriteReply\", \"ConversationHandler\")\n",
        "workflow.add_conditional_edges(\"ConversationHandler\", lambda x: x[\"next\"])\n",
        "workflow.add_edge(\"FollowUpAnalyzer\", \"RetrieveDocs\")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()\n",
        "\n",
        "# Gradio Interface\n",
        "def run_chatbot(age, gender, emotion, query):\n",
        "    try:\n",
        "        input_state = {\n",
        "            \"age\": int(age),\n",
        "            \"gender\": gender,\n",
        "            \"emotion\": emotion,\n",
        "            \"query\": query,\n",
        "            \"messages\": [],\n",
        "            \"docs\": []\n",
        "        }\n",
        "        result = app.invoke(input_state)\n",
        "        reply = result[\"messages\"][-1].content if result[\"messages\"] else \"No response generated.\"\n",
        "        return reply\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Chatbot error: {str(e)}\")\n",
        "        return f\"‚ö†Ô∏è Error occurred: {str(e)}\"\n",
        "\n",
        "gr.Interface(\n",
        "    fn=run_chatbot,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Age\"),\n",
        "        gr.Radio(choices=[\"male\", \"female\"], label=\"Gender\"),\n",
        "        gr.Dropdown(\n",
        "            choices=[\n",
        "                \"stress\", \"anxiety\", \"depression\", \"sadness\", \"overwhelmed\",\n",
        "                \"burnout\", \"anger\", \"lonely\", \"confused\", \"neutral / unsure\"\n",
        "            ],\n",
        "            label=\"Emotion\"\n",
        "        ),\n",
        "        gr.Textbox(lines=3, label=\"What‚Äôs on your mind?\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"üß† GreenLife Health Chatbot ü§ñ\",\n",
        "    description=\"Fill in your details and ask what's bothering you. The chatbot will offer empathetic support and suggestions.\"\n",
        ").launch()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    initial_state = {\n",
        "        \"age\": 50,\n",
        "        \"gender\": \"female\",\n",
        "        \"emotion\": \"stress\",\n",
        "        \"query\": \"I'm feeling very overwhelmed with work and can't focus.\",\n",
        "        \"messages\": [],\n",
        "        \"docs\": []\n",
        "    }\n",
        "    final_result = app.invoke(initial_state)\n",
        "    print(final_result[\"messages\"][-1].content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpYi1ggH5C1V"
      },
      "source": [
        "**SPANISH**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ODjIQMv12CHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b54ee4a-5fb9-4ea0-a1c2-9e94b539bff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Response: {'messages': [], 'age': 28, 'gender': 'hombre', 'language': 'spanish', 'emotion': 'ansioso', 'query': 'Me siento triste, acabo de romper con mi novia', 'docs': [], 'next': '__end__'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "initial_state = {\n",
        "    \"age\": 28,\n",
        "    \"gender\": \"hombre\",\n",
        "    \"emotion\": \"ansioso\",\n",
        "    \"query\": \"Me siento triste, acabo de romper con mi novia\",\n",
        "    \"messages\": [],\n",
        "    \"docs\": [],\n",
        "    \"language\":\"spanish\"\n",
        "}\n",
        "\n",
        "final_result = app.invoke(initial_state)\n",
        "print(\"Final Response:\", final_result)\n",
        "#print(final_result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFTQDMMZSpjE"
      },
      "source": [
        "## **GRAPH VISUALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UeO-thzZFJr0"
      },
      "outputs": [],
      "source": [
        "# !apt-get install -y graphviz libgraphviz-dev\n",
        "# !pip install pygraphviz langgraph[visualizations]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "Ew43-ASNHieF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bdebbce-a3ae-493a-dbda-74abdacfa312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__(<p>__start__</p>)\n",
            "\tInputCollector(InputCollector)\n",
            "\tValidateInput(ValidateInput)\n",
            "\tRetrieveDocs(RetrieveDocs)\n",
            "\tSystemRepliesGenerator(SystemRepliesGenerator)\n",
            "\tRewriteReply(RewriteReply)\n",
            "\tConversationHandler(ConversationHandler)\n",
            "\tFollowUpAnalyzer(FollowUpAnalyzer)\n",
            "\t__end__(<p>__end__</p>)\n",
            "\tInputCollector --> ValidateInput;\n",
            "\t__start__ --> InputCollector;\n",
            "\tValidateInput --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables.graph_mermaid import MermaidDrawMethod\n",
        "# Extrae el c√≥digo Mermaid desde tu objeto\n",
        "mermaid_code = app.get_graph().draw_mermaid()\n",
        "\n",
        "# Muestra el c√≥digo Mermaid en la consola\n",
        "print(mermaid_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Speech to Text**"
      ],
      "metadata": {
        "id": "egIjZt5jJNWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4jYCyY6y1yT8"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import os\n",
        "import whisper\n",
        "whisper_model = whisper.load_model(\"base\")  # you can also try \"small\" or \"medium\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text to Speech**"
      ],
      "metadata": {
        "id": "xDcJ6zNEJnAH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "s2hNpCgZ_1KV"
      },
      "outputs": [],
      "source": [
        "from gtts import gTTS\n",
        "import tempfile\n",
        "import gradio as gr\n",
        "\n",
        "def run_chatbot_with_audio(age, gender, emotion, query_text, audio_path):\n",
        "    try:\n",
        "        # Transcribe if audio is present\n",
        "        if audio_path:\n",
        "            transcription = whisper_model.transcribe(audio_path)\n",
        "            query_text = transcription[\"text\"].strip()\n",
        "\n",
        "        if not query_text:\n",
        "            return \"‚ö†Ô∏è Please speak or type your message.\", None\n",
        "\n",
        "        # Prepare chatbot input\n",
        "        input_state = {\n",
        "            \"age\": int(age),\n",
        "            \"gender\": gender,\n",
        "            \"emotion\": emotion,\n",
        "            \"query\": query_text,\n",
        "            \"messages\": [],\n",
        "            \"docs\": []\n",
        "        }\n",
        "\n",
        "        # Generate response\n",
        "        result = app.invoke(input_state)\n",
        "        reply = result[\"messages\"][-1].content if result[\"messages\"] else \"No response generated.\"\n",
        "\n",
        "        # Convert reply to speech\n",
        "        tts = gTTS(reply)\n",
        "        tts_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "        tts.save(tts_file.name)\n",
        "\n",
        "        return f\"üó£Ô∏è You said: \\\"{query_text}\\\"\\nü§ñ Chatbot: {reply}\", tts_file.name\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Error occurred: {str(e)}\", None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "yDJEaBaPCc9k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "c4c1b42f-b999-40c7-ab74-07827ad36e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e726489517f4ed9315.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e726489517f4ed9315.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "gr.Interface(\n",
        "    fn=run_chatbot_with_audio,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Age\"),\n",
        "        gr.Radio(choices=[\"male\", \"female\"], label=\"Gender\"),\n",
        "        gr.Dropdown(\n",
        "            choices=[\n",
        "                \"stress\", \"anxiety\", \"depression\", \"sadness\", \"overwhelmed\",\n",
        "                \"burnout\", \"anger\", \"lonely\", \"confused\", \"neutral / unsure\"\n",
        "            ],\n",
        "            label=\"Emotion\"\n",
        "        ),\n",
        "        gr.Textbox(lines=3, label=\"üìù Or type your message\"),\n",
        "        gr.Audio(label=\"üé§ Or speak (mic/upload)\", type=\"filepath\", format=\"wav\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Chatbot Reply\"),\n",
        "        gr.Audio(label=\"üîä Chatbot Speaks\")\n",
        "    ],\n",
        "    title=\"üß† GreenLife Health Chatbot üéôÔ∏è\",\n",
        "    description=\"Type or speak your thoughts. The chatbot will respond with empathy and voice.\"\n",
        ").launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VXgaEqECmsf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}